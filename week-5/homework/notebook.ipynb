{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import dayofmonth\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/06 16:31:15 WARN Utils: Your hostname, USERs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.11.129 instead (on interface en0)\n",
      "23/03/06 16:31:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/06 16:31:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/03/06 16:31:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/03/06 16:31:21 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "            .master(\"local[*]\")\\\n",
    "            .appName(\"assignment-notebook\")\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-06 14:51:05--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/4564ad9e-a6da-4923-ad6f-35ff02446a51?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230306%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230306T135108Z&X-Amz-Expires=300&X-Amz-Signature=5473db370e43548381ba9895119ade967ace1a686a88c77a65a35245993eafe9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-06.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-03-06 14:51:06--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/4564ad9e-a6da-4923-ad6f-35ff02446a51?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230306%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230306T135108Z&X-Amz-Expires=300&X-Amz-Signature=5473db370e43548381ba9895119ade967ace1a686a88c77a65a35245993eafe9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-06.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 175799316 (168M) [application/octet-stream]\n",
      "Saving to: ‘fhvhv_tripdata_2021-06.csv.gz’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 167.66M  2.13MB/s    in 2m 42s  \n",
      "\n",
      "2023-03-06 14:53:50 (1.03 MB/s) - ‘fhvhv_tripdata_2021-06.csv.gz’ saved [175799316/175799316]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:02:41</td>\n",
       "      <td>2021-06-01 00:07:46</td>\n",
       "      <td>174</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:16:16</td>\n",
       "      <td>2021-06-01 00:21:14</td>\n",
       "      <td>32</td>\n",
       "      <td>254</td>\n",
       "      <td>N</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:27:01</td>\n",
       "      <td>2021-06-01 00:42:11</td>\n",
       "      <td>240</td>\n",
       "      <td>127</td>\n",
       "      <td>N</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:46:08</td>\n",
       "      <td>2021-06-01 00:53:45</td>\n",
       "      <td>127</td>\n",
       "      <td>235</td>\n",
       "      <td>N</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B02510</td>\n",
       "      <td>2021-06-01 00:45:42</td>\n",
       "      <td>2021-06-01 01:03:33</td>\n",
       "      <td>144</td>\n",
       "      <td>146</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num      pickup_datetime     dropoff_datetime  \\\n",
       "0               B02764  2021-06-01 00:02:41  2021-06-01 00:07:46   \n",
       "1               B02764  2021-06-01 00:16:16  2021-06-01 00:21:14   \n",
       "2               B02764  2021-06-01 00:27:01  2021-06-01 00:42:11   \n",
       "3               B02764  2021-06-01 00:46:08  2021-06-01 00:53:45   \n",
       "4               B02510  2021-06-01 00:45:42  2021-06-01 01:03:33   \n",
       "\n",
       "   PULocationID  DOLocationID SR_Flag Affiliated_base_number  \n",
       "0           174            18       N                 B02764  \n",
       "1            32           254       N                 B02764  \n",
       "2           240           127       N                 B02764  \n",
       "3           127           235       N                 B02764  \n",
       "4           144           146       N                    NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('fhvhv_tripdata_2021-06.csv.gz')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14961892, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num      object\n",
       "pickup_datetime           object\n",
       "dropoff_datetime          object\n",
       "PULocationID               int64\n",
       "DOLocationID               int64\n",
       "SR_Flag                   object\n",
       "Affiliated_base_number    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhvhv_schema = StructType([\n",
    "    StructField(\"dispatching_base_num\", StringType(), True),\n",
    "    StructField(\"pickup_datetime\", TimestampType(), True),\n",
    "    StructField(\"dropoff_datetime\", TimestampType(), True),\n",
    "    StructField(\"PULocationID\", IntegerType(), True),\n",
    "    StructField(\"DOLocationID\", IntegerType(), True),\n",
    "    StructField(\"SR_Flag\", IntegerType(), True),\n",
    "    StructField(\"Affiliated_base_number\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhvhv = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .schema(fhvhv_schema)\\\n",
    "    .csv(\"fhvhv_tripdata_2021-06.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhvhv.createOrReplaceTempView('fhvhv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID        Borough                     Zone service_zone\n",
       "0           1            EWR           Newark Airport          EWR\n",
       "1           2         Queens              Jamaica Bay    Boro Zone\n",
       "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3           4      Manhattan            Alphabet City  Yellow Zone\n",
       "4           5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_path = \"../code/taxi+_zone_lookup.csv\"\n",
    "df_zones = pd.read_csv(taxi_path)\n",
    "df_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocationID       int64\n",
       "Borough         object\n",
       "Zone            object\n",
       "service_zone    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_schema = StructType([\n",
    "    StructField(\"LocationID\", IntegerType(), True),\n",
    "    StructField(\"Borough\", StringType(), True),\n",
    "    StructField(\"Zone\", StringType(), True),\n",
    "    StructField(\"service_zone\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = spark.read\\\n",
    "        .option(\"header\", True)\\\n",
    "        .schema(zones_schema)\\\n",
    "        .csv(taxi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones.createOrReplaceTempView('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"\"\"\n",
    "\n",
    "#     SELECT \n",
    "#         dispatching_base_num,\n",
    "#         Affiliated_base_number as affiliated_base_num,\n",
    "#         PULocationID as pickup_location_id,\n",
    "#         DOLocationID as dropoff_location_id,\n",
    "#         SR_Flag as sr_flag,\n",
    "#         pickup_datetime,\n",
    "#         dropoff_datetime\n",
    "#     FROM \n",
    "#         fhvhv\n",
    "    \n",
    "# \"\"\").createOrReplaceTempView('fhvhv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"SELECT * FROM fhvhv\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  452470|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    count(*)\n",
    "FROM\n",
    "    fhvhv\n",
    "WHERE \n",
    "    pickup_datetime >= \"2021-06-15 00:00:00\"\n",
    "    AND\n",
    "    pickup_datetime < \"2021-06-16 00:00:00\"\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhvhv = fhvhv.repartition(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02884|2021-06-29 07:42:05|2021-06-29 07:53:43|          69|         159|   null|                B02884|\n",
      "|              B02510|2021-06-14 00:15:32|2021-06-14 00:25:17|         231|         232|   null|                  null|\n",
      "|              B02764|2021-06-10 00:30:05|2021-06-10 01:11:16|         230|         117|   null|                B02764|\n",
      "|              B02877|2021-06-06 06:58:20|2021-06-06 07:32:26|         132|          25|   null|                B02877|\n",
      "|              B02764|2021-06-02 13:55:25|2021-06-02 14:28:05|          95|         237|   null|                B02764|\n",
      "|              B02682|2021-06-07 06:49:20|2021-06-07 07:32:19|          80|           1|   null|                B02682|\n",
      "|              B02870|2021-06-05 15:29:02|2021-06-05 16:00:58|          70|         130|   null|                B02870|\n",
      "|              B02510|2021-06-08 16:19:49|2021-06-08 16:53:45|         223|         223|   null|                  null|\n",
      "|              B02764|2021-06-16 14:52:53|2021-06-16 15:49:54|         138|         265|   null|                B02764|\n",
      "|              B02617|2021-06-02 00:05:19|2021-06-02 00:19:39|         148|         237|   null|                B02617|\n",
      "|              B02510|2021-06-30 20:14:19|2021-06-30 20:25:54|          50|         164|   null|                  null|\n",
      "|              B02765|2021-06-10 16:40:47|2021-06-10 16:52:32|         161|         186|   null|                B02765|\n",
      "|              B02872|2021-06-10 03:55:05|2021-06-10 04:32:55|          76|          50|   null|                B02872|\n",
      "|              B02879|2021-06-17 17:47:29|2021-06-17 19:02:58|         254|          72|   null|                B02879|\n",
      "|              B02875|2021-06-26 05:58:46|2021-06-26 06:15:06|          69|          94|   null|                B02875|\n",
      "|              B02510|2021-06-06 23:31:59|2021-06-06 23:41:28|         218|         215|   null|                  null|\n",
      "|              B02869|2021-06-12 17:29:05|2021-06-12 17:58:32|         138|         163|   null|                B02869|\n",
      "|              B02510|2021-06-20 22:55:20|2021-06-20 23:09:44|         168|          74|   null|                  null|\n",
      "|              B02765|2021-06-05 12:42:54|2021-06-05 12:53:42|          95|          95|   null|                B02765|\n",
      "|              B02765|2021-06-20 10:44:15|2021-06-20 11:10:32|         121|          37|   null|                B02765|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fhvhv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fhvhv.write\\\n",
    "    .parquet(\"fhvhv/2021/01/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 581512\n",
      "-rw-r--r--  1 user  staff     0B Mar  6 16:47 _SUCCESS\n",
      "-rw-r--r--  1 user  staff    24M Mar  6 16:47 part-00000-17d25cbc-219a-4087-b003-96c8ed4b4f22-c000.snappy.parquet\n",
      "-rw-r--r--  1 user  staff    24M Mar  6 16:47 part-00001-17d25cbc-219a-4087-b003-96c8ed4b4f22-c000.snappy.parquet\n",
      "-rw-r--r--  1 user  staff    24M Mar  6 16:47 part-00002-17d25cbc-219a-4087-b003-96c8ed4b4f22-c000.snappy.parquet\n",
      "-rw-r--r--  1 user  staff    24M Mar  6 16:47 part-00003-17d25cbc-219a-4087-b003-96c8ed4b4f22-c000.snappy.parquet\n",
      "-rw-r--r--  1 user  staff    24M Mar  6 16:47 part-00004-17d25cbc-219a-4087-b003-96c8ed4b4f22-c000.snappy.parquet\n",
      "-rw-r--r--  1 user  staff    24M Mar  6 16:47 part-00005-17d25cbc-219a-4087-b003-96c8ed4b4f22-c000.snappy.parquet\n",
      "-rw-r--r--  1 user  staff    24M Mar  6 16:47 part-00006-17d25cbc-219a-4087-b003-96c8ed4b4f22-c000.snappy.parquet\n",
      "-rw-r--r--  1 user  staff    24M Mar  6 16:47 part-00007-17d25cbc-219a-4087-b003-96c8ed4b4f22-c000.snappy.parquet\n",
      "-rw-r--r--  1 user  staff    24M Mar  6 16:47 part-00008-17d25cbc-219a-4087-b003-96c8ed4b4f22-c000.snappy.parquet\n",
      "-rw-r--r--  1 user  staff    24M Mar  6 16:47 part-00009-17d25cbc-219a-4087-b003-96c8ed4b4f22-c000.snappy.parquet\n",
      "-rw-r--r--  1 user  staff    24M Mar  6 16:47 part-00010-17d25cbc-219a-4087-b003-96c8ed4b4f22-c000.snappy.parquet\n",
      "-rw-r--r--  1 user  staff    24M Mar  6 16:47 part-00011-17d25cbc-219a-4087-b003-96c8ed4b4f22-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh fhvhv/2021/01/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  452470|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*)\n",
    "    FROM \n",
    "        fhvhv\n",
    "    WHERE \n",
    "        pickup_datetime >= '2021-06-15 00:00:00' AND pickup_datetime < '2021-06-16 00:00:00'\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+\n",
      "|day_of_month|num_trips|\n",
      "+------------+---------+\n",
      "|          15|   452470|\n",
      "+------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "    WITH tripdata AS (\n",
    "        SELECT\n",
    "            dayofmonth(pickup_datetime) as day_of_month,\n",
    "            count(1) as num_trips\n",
    "        FROM\n",
    "            fhvhv\n",
    "        GROUP BY\n",
    "            dayofmonth(pickup_datetime)\n",
    "    )\n",
    "    \n",
    "    SELECT * \n",
    "    FROM tripdata td\n",
    "    WHERE td.day_of_month = 15\n",
    "    \n",
    "\"\"\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/06 16:58:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/03/06 16:58:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/03/06 16:58:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/06 16:59:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/03/06 16:59:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|duration_in_hours|\n",
      "+-----------------+\n",
      "|            66.88|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "    WITH tripdata AS (\n",
    "        SELECT\n",
    "            PULocationID,\n",
    "            DOLocationID\n",
    "            pickup_datetime,\n",
    "            dropoff_datetime,\n",
    "            (CAST(dropoff_datetime as LONG) - CAST(pickup_datetime as LONG)) as duration_in_secs\n",
    "        FROM\n",
    "            fhvhv\n",
    "    ),\n",
    "    \n",
    "    trip_duration AS (\n",
    "        SELECT \n",
    "            (duration_in_secs/3600) as duration_in_hours,\n",
    "            dense_rank() OVER( ORDER BY duration_in_secs DESC ) as rnk\n",
    "        FROM \n",
    "            tripdata\n",
    "    )\n",
    "    \n",
    "    SELECT \n",
    "        ROUND(td.duration_in_hours, 2) as duration_in_hours\n",
    "    FROM \n",
    "        trip_duration td\n",
    "    WHERE\n",
    "        td.rnk = 1\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have set the Spark in a PATH then just enter **pyspark** in command line or terminal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "23/03/05 10:17:37 WARN Utils: Your hostname, USERs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.83.129 instead (on interface en0)\n",
    "23/03/05 10:17:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
    "Setting default log level to \"WARN\".\n",
    "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
    "23/03/05 10:17:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
    "Spark context Web UI available at http://192.168.83.129:4040\n",
    "Spark context available as 'sc' (master = local[*], app id = local-1678007867731).\n",
    "Spark session available as 'spark'.\n",
    "Welcome to\n",
    "      ____              __\n",
    "     / __/__  ___ _____/ /__\n",
    "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
    "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.3.2\n",
    "      /_/\n",
    "         \n",
    "Using Scala version 2.12.15 (OpenJDK 64-Bit Server VM, Java 19.0.2)\n",
    "Type in expressions to have them evaluated.\n",
    "Type :help for more information.\n",
    "```\n",
    "\n",
    "```\n",
    "scala> spark.version\n",
    "res0: String = 3.3.2\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/06 16:59:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/03/06 16:59:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/03/06 16:59:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/03/06 16:59:34 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/06 16:59:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/03/06 16:59:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/03/06 16:59:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/03/06 16:59:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "+------------+-------------------+---------+----+\n",
      "|PULocationID|               Zone|num_trips|rank|\n",
      "+------------+-------------------+---------+----+\n",
      "|          61|Crown Heights North|   231279|   1|\n",
      "+------------+-------------------+---------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    \n",
    "    WITH trip_count_per_location AS (\n",
    "        SELECT \n",
    "            f.PULocationID,\n",
    "            count(1) as num_trips,\n",
    "            dense_rank() over (order by count(1) desc) as rnk\n",
    "        FROM \n",
    "            fhvhv f\n",
    "        GROUP BY \n",
    "            f.PULocationID\n",
    "    ) \n",
    "    \n",
    "    SELECT \n",
    "        tl.PULocationID,\n",
    "        z.Zone,\n",
    "        tl.num_trips,\n",
    "        tl.rnk rank\n",
    "    FROM \n",
    "        trip_count_per_location tl\n",
    "    INNER JOIN \n",
    "        zones z ON tl.PULocationID = z.LocationID\n",
    "    WHERE \n",
    "        tl.rnk = 1\n",
    "    \n",
    "\"\"\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">Merci Beaucoup!</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
